{
  "name": "Fall2016-project-cesiu",
  "tagline": "fall2016-project-cesiu created by GitHub Classroom",
  "body": "[![Build Status](https://travis-ci.org/cpe305/fall2016-project-cesiu.svg?branch=master)](https://travis-ci.org/cpe305/fall2016-project-cesiu)\r\n\r\nSmartRochambeau is a single player Rock-Paper-Scissors game featuring four\r\ndifferent AI opponents, developed as an individual project for Professor\r\nGudrun Socher's CPE 305 at Cal Poly, Fall 2016.\r\n\r\nSmartRochambeau can be run by double clicking on the JAR or from the command \r\nline using java -jar SmartRochambeau.jar.\r\n\r\nSmartRochambeau keeps track of win-loss-tie statistics and supports saved games.\r\n\r\nSmartRochambeau features four AI opponents:\r\n* A random AI as a control, which simply selects a random throw every round.\r\n* A Markov Chain AI modeled using nine states and three intermediate states, \r\n  which answers the question, \"Considering what the player threw last and \r\n  whether or not he won, what is he likely to throw next?\". At any given time, \r\n  the current state is determined by the player's last throw and the result of \r\n  that round, e.g., \"Rock, win\". Each state contains frequencies logging how \r\n  often, when the game is at that current state, the player has moved according \r\n  to each of the three intermediate states, which contain only a throw, e.g., \r\n  \"Paper\". For example, the state \"Rock, win\" would contain three numbers \r\n  corresponding to how often, after playing Rock and winning, the player then \r\n  threw Rock, Paper, and Scissors. Based on those numbers, the AI can predict \r\n  the player's most likely next move. The AI trains as it runs, updating the \r\n  frequencies once it knows the outcome of the current round before it moves to\r\n  the next state.\r\n* A Naive Bayes AI -- implemented mostly as an experiment, not because I thought\r\n  it was necessarily a good algorithm for this problem -- that attempts to\r\n  answer the question, \"Considering the player's last few throws, what is he\r\n  leading up to throwing?\". The idea being, a Markov-Chain-based is vulnerable\r\n  because Rock-Paper-Scissors doesn't really satisfy the Markov Property; what\r\n  the player does next is not solely dependant on what he did last. The Naive\r\n  Bayes AI attempts to defeat 'longer' strategies wherein the player makes a\r\n  few moves to set his opponent up for a later move. The AI maintains a queue\r\n  of the player's last few throws as well as nine frequencies for how often each\r\n  individual throw 'led up to' each of the other throws. For example, if the\r\n  last three throws were \"Rock, Paper, Rock\", the AI can look at how often,\r\n  historically, Rock and Paper have indivdually led up to Rock, Paper, or\r\n  Scissors, then combine those probabilities using Bayes Rule. Like the Markov\r\n  Chain AI, the Naive Bayes AI is capable of training as it goes, though this\r\n  makes it vulnerable to overfitting and thus long term shifts in strategy.\r\n* A Pattern Matching AI, which I personally predicted would do best of the \r\n  three, that attempts to answer the same question as the Naive Bayes AI, but\r\n  based on the pattern of the individual throws, not their general overall\r\n  frequencies. The AI maintains a complete ternary tree of throws to allow\r\n  for faster pattern matching, with each possible pattern represented as a\r\n  unique path from root to a leaf, and each leaf, as you might expect, contains\r\n  frequencies for each of the three throws. The Pattern Matching AI, too, is\r\n  capable of training as it runs..\r\n  \r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}