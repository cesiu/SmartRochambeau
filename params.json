{
  "name": "Fall2016-project-cesiu",
  "tagline": "fall2016-project-cesiu created by GitHub Classroom",
  "body": "[![Build Status](https://travis-ci.org/cpe305/fall2016-project-cesiu.svg?branch=master)](https://travis-ci.org/cpe305/fall2016-project-cesiu)\r\n\r\n![ui mock](https://github.com/cpe305/fall2016-project-cesiu/blob/master/diagrams/GameScreen.png?raw=true)\r\n\r\nSmartRochambeau is a single player Rock-Paper-Scissors game featuring four\r\ndifferent AI opponents, developed as an individual project for Professor\r\nGudrun Socher's CPE 305 at Cal Poly, Fall 2016.\r\n\r\n## Installing\r\nOnly the cross-platform SmartRochambeau.jar is required to run the game.\r\n\r\n## Running\r\nSmartRochambeau can be run by double clicking on the JAR or from the command \r\nline using `java -jar SmartRochambeau.jar`.\r\n\r\nSmartRochambeau keeps track of win-loss-tie statistics and supports saved games.\r\n\r\n## Opponents\r\nSmartRochambeau features four AI opponents:\r\n* A random AI as a control, which simply selects a random throw every round.\r\n* A Markov Chain AI modeled using nine states and three intermediate states, \r\n  which answers the question, \"Considering what the player threw last and \r\n  whether or not he won, what is he likely to throw next?\". At any given time, \r\n  the current state is determined by the player's last throw and the result of \r\n  that round, e.g., \"Rock, win\". Each state contains frequencies logging how \r\n  often, when the game is at that current state, the player has moved according \r\n  to each of the three intermediate states, which contain only a throw, e.g., \r\n  \"Paper\". For example, the state \"Rock, win\" would contain three numbers \r\n  corresponding to how often, after playing Rock and winning, the player then \r\n  threw Rock, Paper, and Scissors. Based on those numbers, the AI can predict \r\n  the player's most likely next move. The AI trains as it runs, updating the \r\n  frequencies once it knows the outcome of the current round before it moves to\r\n  the next state.\r\n* A Naive Bayes AI -- implemented mostly as an experiment, not because I thought\r\n  it was necessarily a good algorithm for this problem -- that attempts to\r\n  answer the question, \"Considering the player's last few throws, what is he\r\n  leading up to throwing?\". The idea being, a Markov-Chain-based is vulnerable\r\n  because Rock-Paper-Scissors doesn't really satisfy the Markov Property; what\r\n  the player does next is not solely dependant on what he did last. The Naive\r\n  Bayes AI attempts to defeat 'longer' strategies wherein the player makes a\r\n  few moves to set his opponent up for a later move. The AI maintains a queue\r\n  of the player's last few throws as well as nine frequencies for how often each\r\n  individual throw 'led up to' each of the other throws. For example, if the\r\n  last three throws were \"Rock, Paper, Rock\", the AI can look at how often,\r\n  historically, Rock and Paper have indivdually led up to Rock, Paper, or\r\n  Scissors, then combine those probabilities using Bayes Rule. Like the Markov\r\n  Chain AI, the Naive Bayes AI is capable of training as it goes, though this\r\n  makes it vulnerable to overfitting and thus long term shifts in strategy.\r\n* A Pattern Matching AI, which I personally predicted would do best of the \r\n  three, that attempts to answer the same question as the Naive Bayes AI, but\r\n  based on the pattern of the individual throws, not their general overall\r\n  frequencies. The AI maintains a complete ternary tree of throws to allow\r\n  for faster pattern matching, with each possible pattern represented as a\r\n  unique path from root to a leaf, and each leaf, as you might expect, contains\r\n  frequencies for each of the three throws. The Pattern Matching AI, too, is\r\n  capable of training as it runs..\r\n\r\nThese AI all share a common drawback: training as they go makes them easy to\r\nset up and play immediately, but it makes them vulnerable to overfitting. A\r\nplayer might make a slight change to his strategy, and the AI might take\r\na long time to catch up.\r\n\r\nOne possible solution is to count how many times the AI has used a throw for \r\ntraining. After a certain threshold, whether that be related to number of throws\r\ntrained on, win rate, or some combination thereof, the AI stops saving\r\ninformation after each round. After a certain amount of time or after the win\r\nrate drops below some other threshold, the AI can start training again, perhaps\r\npartially or completely \"wiping the slate\" and deleting some or all of its saved\r\ninformation.\r\n\r\n## Architecture\r\n\r\n![class diagram](https://github.com/cpe305/fall2016-project-cesiu/blob/master/diagrams/classDiagram.png?raw=true)\r\n\r\nSmartRochambeau uses a modified Model-View-Controller architecture pattern, with\r\na controller class providing a generalized interface to the UI for the core\r\nlogic and also giving the UI access to methods of the core logic. Both the UI\r\nand the AI implement interfaces designed to make adding new machine learning AI\r\neasy. \r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}